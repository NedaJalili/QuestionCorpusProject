import json
from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np
import scipy.sparse
import os

input_path = "output/formatted_articles.jsonl"  # Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ ÙˆØ±ÙˆØ¯ÛŒ


# Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ÙØ§ÛŒÙ„
if not os.path.exists(input_path):
    print(f"ÙØ§ÛŒÙ„ {input_path} ÛŒØ§ÙØª Ù†Ø´Ø¯.")
else:
    # Ø®ÙˆØ§Ù†Ø¯Ù† Ù…Ù‚Ø§Ù„Ø§Øª Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡
    documents = []
    with open(input_path, "r", encoding="utf-8") as file:
        for line in file:
            data = json.loads(line)
            documents.append(data["raw_test"])  # Ø¯Ø±ÛŒØ§ÙØª Ù…ØªÙ† Ù…Ù‚Ø§Ù„Ù‡

    # ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ†â€ŒÙ‡Ø§ Ø¨Ù‡ Ù…Ø§ØªØ±ÛŒØ³ ØªØ±Ù…-Ø¯Ø§Ú©ÛŒÙˆÙ…Ù†Øª Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² TF-IDF
    vectorizer = TfidfVectorizer(max_features=5000, stop_words=None)  # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ù‡ 5000 Ú©Ù„Ù…Ù‡ Ù…Ù‡Ù…
    X = vectorizer.fit_transform(documents)

    # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø§ØªØ±ÛŒØ³ Ø¨Ù‡ ØµÙˆØ±Øª ÙØ´Ø±Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ
    scipy.sparse.save_npz("output/tdm_matrix.npz", X)

    # Ø°Ø®ÛŒØ±Ù‡ ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ (ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø§ØªØ±ÛŒØ³) 
    with open("output/tdm_features.json", "w", encoding="utf-8") as f:
        json.dump(vectorizer.get_feature_names_out().tolist(), f, ensure_ascii=False)

    print("  Ù…Ø§ØªØ±ÛŒØ³ ØªØ±Ù…-Ø¯Ø§Ú©ÛŒÙˆÙ…Ù†Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø³Ø§Ø®ØªÙ‡ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
    print("ğŸ”¹ Ø§Ø¨Ø¹Ø§Ø¯ Ù…Ø§ØªØ±ÛŒØ³:", X.shape)  # (ØªØ¹Ø¯Ø§Ø¯ Ù…Ù‚Ø§Ù„Ø§Øª, ØªØ¹Ø¯Ø§Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§)
