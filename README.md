QuestionCorpusProject
Ù…Ø¹Ø±ÙÛŒ Ù¾Ø±ÙˆÚ˜Ù‡
QuestionCorpusProject ÛŒÚ© Ø³ÛŒØ³ØªÙ… Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† Ø§Ø³Øª Ú©Ù‡ Ø´Ø§Ù…Ù„ Ù…Ø±Ø§Ø­Ù„ Ù…Ø®ØªÙ„ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒØŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø² Ù…Ù‚Ø§Ù„Ø§Øª Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯. Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ø§ Ù‡Ø¯Ù ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²Ø¨Ø§Ù† Ø·Ø¨ÛŒØ¹ÛŒ (NLP) Ùˆ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø³Ø´ Ùˆ Ù¾Ø§Ø³Ø® Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª.
________________________________________
ğŸ“ Ø³Ø§Ø®ØªØ§Ø± Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡
data/
Ù…Ø­ØªÙˆØ§: Ù…Ù‚Ø§Ù„Ø§Øª Ø®Ø§Ù… Ø¯Ø±ÛŒØ§ÙØªâ€ŒØ´Ø¯Ù‡ Ø§Ø² ÙˆØ¨â€ŒØ³Ø§ÛŒØª
â€¢	raw_articles.jsonl â†’ Ù…Ù‚Ø§Ù„Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø¯ÙˆÙ† Ù¾Ø±Ø¯Ø§Ø²Ø´
output/
Ù…Ø­ØªÙˆØ§: Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡
â€¢	articles_cleaned.jsonl â†’ Ù…Ù‚Ø§Ù„Ø§Øª Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡
â€¢	formatted_articles.jsonl â†’ Ù…Ù‚Ø§Ù„Ø§Øª ÙØ±Ù…Øªâ€ŒÛŒØ§ÙØªÙ‡ Ø¯Ø± Ù‚Ø§Ù„Ø¨ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ
â€¢	tdm_matrix.npz â†’ Ù…Ø§ØªØ±ÛŒØ³ ØªØ±Ù…-Ø¯Ø§Ú©ÛŒÙˆÙ…Ù†Øª
â€¢	tdm_features.json â†’ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒØ´Ø¯Ù‡ (Ú©Ù„Ù…Ø§Øª Ù…Ù‡Ù…)
â€¢	document_similarities.json â†’ Ø´Ø¨Ø§Ù‡Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡â€ŒØ´Ø¯Ù‡ Ø¨ÛŒÙ† Ù…Ù‚Ø§Ù„Ø§Øª
â€¢	final_dataset.jsonl â†’ Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ø´Ø§Ù…Ù„ Ø³ÙˆØ§Ù„Ø§Øª Ùˆ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§
scripts/
Ù…Ø­ØªÙˆØ§: Ø§Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ†
â€¢	crawler.py â†’ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù‚Ø§Ù„Ø§Øª Ø§Ø² ÙˆØ¨â€ŒØ³Ø§ÛŒØª
â€¢	preprocess.py â†’ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† (Ø­Ø°Ù Ù†ÙˆÛŒØ²Ù‡Ø§ Ùˆ Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ)
â€¢	format_articles.py â†’ ÙØ±Ù…Øªâ€ŒØ¯Ù‡ÛŒ Ù…Ù‚Ø§Ù„Ø§Øª Ø¯Ø± Ù‚Ø§Ù„Ø¨ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ
â€¢	build_tdm.py â†’ Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø§ØªØ±ÛŒØ³ ØªØ±Ù…-Ø¯Ø§Ú©ÛŒÙˆÙ…Ù†Øª
â€¢	document_similarity_cosine.py â†’ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª Ú©Ø³ÛŒÙ†ÙˆØ³ÛŒ Ù…Ù‚Ø§Ù„Ø§Øª
â€¢	generate_questions.py â†’ ØªÙˆÙ„ÛŒØ¯ Ø³ÙˆØ§Ù„ Ùˆ Ø¬ÙˆØ§Ø¨ Ø§Ø² Ù…Ù‚Ø§Ù„Ø§Øª
Ø³Ø§ÛŒØ± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
â€¢	crawler_errors.log â†’ Ø«Ø¨Øª Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ crawler.py
â€¢	README.md â†’ ØªÙˆØ¶ÛŒØ­Ø§Øª Ù¾Ø±ÙˆÚ˜Ù‡
________________________________________
ğŸ”¹ Ù…Ø±Ø§Ø­Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
Û±. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù‚Ø§Ù„Ø§Øª
â€¢	Ø¯Ø±ÛŒØ§ÙØª Ù…Ù‚Ø§Ù„Ø§Øª Ø§Ø² ÙˆØ¨â€ŒØ³Ø§ÛŒØª https://fa.wikishia.net Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² crawler.py
â€¢	Ø°Ø®ÛŒØ±Ù‡ Ù…Ù‚Ø§Ù„Ø§Øª Ø¯Ø± Ù¾ÙˆØ´Ù‡ data/
Û². Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
â€¢	Ø­Ø°Ù Ù†ÙˆÛŒØ²Ù‡Ø§ØŒ Ø¹Ù„Ø§Ø¦Ù… Ø§Ø¶Ø§ÙÛŒ Ùˆ Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙˆÙ† Ø¨Ø§ preprocess.py
â€¢	Ø°Ø®ÛŒØ±Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ø¯Ø± output/articles_cleaned.jsonl
Û³. ÙØ±Ù…Øªâ€ŒØ¯Ù‡ÛŒ Ù…Ù‚Ø§Ù„Ø§Øª
â€¢	ØªØ¨Ø¯ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡ Ø¨Ù‡ Ù‚Ø§Ù„Ø¨ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø§ format_articles.py
â€¢	Ø°Ø®ÛŒØ±Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ø¯Ø± output/formatted_articles.jsonl
Û´. Ø³Ø§Ø®Øª Ù…Ø§ØªØ±ÛŒØ³ ØªØ±Ù…-Ø¯Ø§Ú©ÛŒÙˆÙ…Ù†Øª (TDM)
â€¢	Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø§ØªØ±ÛŒØ³ TF-IDF Ø¨Ø§ build_tdm.py
â€¢	Ø°Ø®ÛŒØ±Ù‡ Ù…Ø§ØªØ±ÛŒØ³ Ø¯Ø± output/tdm_matrix.npz
â€¢	Ø°Ø®ÛŒØ±Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒØ´Ø¯Ù‡ Ø¯Ø± output/tdm_features.json
Ûµ. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª Ù…Ù‚Ø§Ù„Ø§Øª
â€¢	Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙØ§ØµÙ„Ù‡ Ú©Ø³ÛŒÙ†ÙˆØ³ÛŒ Ø¨ÛŒÙ† Ù…Ù‚Ø§Ù„Ø§Øª Ø¨Ø§ document_similarity_cosine.py
â€¢	Ø°Ø®ÛŒØ±Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ø¯Ø± output/document_similarities.json
Û¶. ØªÙˆÙ„ÛŒØ¯ Ø³ÙˆØ§Ù„Ø§Øª
â€¢	ØªÙˆÙ„ÛŒØ¯ Ø³ÙˆØ§Ù„ Ùˆ Ø¬ÙˆØ§Ø¨ Ø§Ø² Ù…Ù‚Ø§Ù„Ø§Øª Ø¨Ø§ generate_questions.py
â€¢	Ø°Ø®ÛŒØ±Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ø¯Ø± output/final_dataset.jsonl
________________________________________
  Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§
â€¢	ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ NLP
â€¢	ØªÙˆØ³Ø¹Ù‡ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø³Ø´ Ùˆ Ù¾Ø§Ø³Ø®
â€¢	ØªØ­Ù„ÛŒÙ„ Ø´Ø¨Ø§Ù‡Øª Ù…ØªÙˆÙ† Ùˆ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ù‚Ø§Ù„Ø§Øª
________________________________________
  Ù†Ø­ÙˆÙ‡ Ù…Ø´Ø§Ø±Ú©Øª
Ø§Ú¯Ø± Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ø±Ø§ÛŒ Ø´Ù…Ø§ Ù…ÙÛŒØ¯ Ø¨ÙˆØ¯ØŒ Ù„Ø·ÙØ§Ù‹ Ø¢Ù† Ø±Ø§ â­ Ú©Ù†ÛŒØ¯. Ù‡Ø±Ú¯ÙˆÙ†Ù‡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ ÛŒØ§ Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ø·Ø±ÛŒÙ‚ Pull Request Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.
âœ‰ï¸ Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ù…Ù†: neda.jalili.23@gmail.com
________________________________________
________________________________________
QuestionCorpusProject
Project Overview
QuestionCorpusProject is a text processing system designed to collect, process, and extract structured information from articles. The goal is to create structured datasets for NLP models and Q&A systems.
________________________________________
ğŸ“ Project Structure
data/
Content: Raw articles collected from the website
â€¢	raw_articles.jsonl â†’ Unprocessed articles
output/
Content: Processed data outputs
â€¢	articles_cleaned.jsonl â†’ Preprocessed articles
â€¢	formatted_articles.jsonl â†’ Articles formatted as dictionaries
â€¢	tdm_matrix.npz â†’ Term-document matrix
â€¢	tdm_features.json â†’ Extracted features (important words)
â€¢	document_similarities.json â†’ Computed article similarities
â€¢	final_dataset.jsonl â†’ Final dataset with generated Q&A pairs
scripts/
Content: Text processing scripts
â€¢	crawler.py â†’ Extract articles from the website
â€¢	preprocess.py â†’ Clean and preprocess text
â€¢	format_articles.py â†’ Convert articles into structured dictionaries
â€¢	build_tdm.py â†’ Generate term-document matrix
â€¢	document_similarity_cosine.py â†’ Compute cosine similarity between articles
â€¢	generate_questions.py â†’ Generate questions and answers from articles
Other Files
â€¢	crawler_errors.log â†’ Log file for crawler errors
â€¢	README.md â†’ Project documentation
________________________________________
ğŸ”¹ Data Processing Steps
1. Article Extraction
â€¢	Articles are scraped from https://fa.wikishia.net using crawler.py
â€¢	Articles are stored in data/
2. Data Preprocessing
â€¢	Noise removal, text cleaning using preprocess.py
â€¢	Output stored in output/articles_cleaned.jsonl
3. Formatting Articles
â€¢	Convert cleaned data into structured format using format_articles.py
â€¢	Output stored in output/formatted_articles.jsonl
4. Building Term-Document Matrix (TDM)
â€¢	Generate TF-IDF matrix using build_tdm.py
â€¢	Matrix stored in output/tdm_matrix.npz
â€¢	Extracted features stored in output/tdm_features.json
5. Computing Article Similarity
â€¢	Compute cosine similarity between articles using document_similarity_cosine.py
â€¢	Output stored in output/document_similarities.json
6. Generating Questions
â€¢	Generate Q&A pairs using generate_questions.py
â€¢	Output stored in output/final_dataset.jsonl
________________________________________
  Use Cases
â€¢	Generating training data for NLP models
â€¢	Developing Q&A systems
â€¢	Text similarity analysis and article clustering
________________________________________
  Contributing
If you find this project useful, please â­ star it. Feel free to contribute by submitting a Pull Request.
âœ‰ï¸ Contact: neda.jalili.23@gmail.com
